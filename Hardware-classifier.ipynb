{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zd1JPPl0FzD_"
      },
      "outputs": [],
      "source": [
        "# import the necessary libraries\n",
        "\n",
        "import time\n",
        "import gc\n",
        "import os\n",
        "import random\n",
        "\n",
        "random_state = 42\n",
        "os.add_dll_directory(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.2/bin\")\n",
        "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'\n",
        "os.environ['PYTHONHASHSEED'] = str(random_state)\n",
        "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "log_dir = os.path.join(os.curdir, 'logs')\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage import io, util\n",
        "from skimage.color import rgba2rgb\n",
        "from tensorflow import keras\n",
        "\n",
        "random.seed(random_state) # random python seed, but fixed\n",
        "np.random.seed(random_state) # random numpy seed, but fixed\n",
        "tf.random.set_seed(random_state) # random tf seed, but fixed\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "# define the image path\n",
        "img_train_folder_set1 = r'dataset\\pictures\\train\\64x64\\set-1'\n",
        "img_train_folder_set2 = r'dataset\\pictures\\train\\64x64\\set-2'\n",
        "img_test_folder = r'dataset\\pictures\\test\\64x64'\n",
        "\n",
        "# define plot properties for dark IDE\n",
        "# font_size = 25\n",
        "# font_color = 'white'\n",
        "# plt.rc('axes', facecolor = '#1e1e1e')\n",
        "# plt.rc('figure', facecolor = '#1e1e1e')\n",
        "# plt.rc('axes', edgecolor = 'w')\n",
        "# plt.rc('xtick', color = 'w')\n",
        "# plt.rc('ytick', color = 'w')\n",
        "# plt.rc('legend', facecolor = 'w')\n",
        "\n",
        "# define plot properties for light IDE\n",
        "font_size = 25\n",
        "font_color = 'black'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# auxiliary code to visualize the first 10 pictures of each category (SET-1)\n",
        "plt.figure(figsize = (50, 50))\n",
        "j = 0\n",
        "counter_set1 = 0\n",
        "counter_set2 = 0\n",
        "\n",
        "for dir1 in os.listdir(img_train_folder_set1):\n",
        "    for file in os.listdir(os.path.join(img_train_folder_set1, dir1)):\n",
        "        image_path = os.path.join(img_train_folder_set1, dir1, file)  \n",
        "        img = mpimg.imread(image_path)\n",
        "        ax = plt.subplot(10, 10, j+1)\n",
        "        ax.title.set_text(file)\n",
        "        plt.axis('off')\n",
        "        plt.title(dir1, fontsize = font_size, color = font_color)\n",
        "        plt.imshow(img)\n",
        "        j += 1\n",
        "        counter_set1 += 1\n",
        "        if counter_set1 == 10:\n",
        "            break\n",
        "    counter_set2 += 1\n",
        "    counter_set1 = 0\n",
        "    if counter_set2 == 7:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# auxiliary code to visualize the first 10 pictures of each category (SET-2)\n",
        "plt.figure(figsize = (50, 50))\n",
        "j = 0\n",
        "counter_set3 = 0\n",
        "counter_set4 = 0\n",
        "\n",
        "for dir1 in os.listdir(img_train_folder_set2):\n",
        "    for file in os.listdir(os.path.join(img_train_folder_set2, dir1)):\n",
        "        image_path = os.path.join(img_train_folder_set2, dir1, file)  \n",
        "        img = mpimg.imread(image_path)\n",
        "        ax = plt.subplot(10, 10, j+1)\n",
        "        ax.title.set_text(file)\n",
        "        plt.axis('off')\n",
        "        plt.title(dir1, fontsize = font_size, color = font_color)\n",
        "        plt.imshow(img)\n",
        "        j += 1\n",
        "        counter_set3 += 1\n",
        "        if counter_set3 == 10:\n",
        "            break\n",
        "    counter_set4 += 1\n",
        "    counter_set3 = 0\n",
        "    if counter_set4 == 7:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# function to gather pictures and generate a numpy array (COLOR)\n",
        "def create_dataset(img_folder):\n",
        "   \n",
        "    img_data_array = []\n",
        "    class_name = []\n",
        "   \n",
        "    for dir1 in os.listdir(img_folder):\n",
        "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
        "            image_path = os.path.join(img_folder, dir1, file)\n",
        "            image = io.imread(image_path, as_gray = False)\n",
        "            image = np.array(image)\n",
        "            image = rgba2rgb(image)                      \n",
        "            img_data_array.append(image)\n",
        "            class_name.append(int(dir1))\n",
        "    return img_data_array, class_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# function to gather pictures and generate a numpy array (GRAYSCALE)\n",
        "def create_dataset(img_folder):\n",
        "   \n",
        "    img_data_array = []\n",
        "    class_name = []\n",
        "   \n",
        "    for dir1 in os.listdir(img_folder):\n",
        "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
        "            image_path = os.path.join(img_folder, dir1, file)\n",
        "            image = io.imread(image_path, as_gray = True)\n",
        "            image = util.invert(image)\n",
        "            image = np.array(image, dtype = 'float32')\n",
        "            image /= 255\n",
        "            img_data_array.append(image)\n",
        "            class_name.append(int(dir1))\n",
        "    return img_data_array, class_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sets a image generator to inflate the dataset\n",
        "generator = ImageDataGenerator(\n",
        "    rotation_range = 90,\n",
        "    width_shift_range = 0.2, \n",
        "    height_shift_range = 0.2,\n",
        "    fill_mode='constant',\n",
        "    cval=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_valid_size = 0.80\n",
        "i = 0\n",
        "\n",
        "# dataset import\n",
        "X_array1, y_array1 = create_dataset(img_train_folder_set1)\n",
        "X_array2, y_array2 = create_dataset(img_train_folder_set2)\n",
        "\n",
        "X_trainSeq1 = np.array(X_array1)\n",
        "y_trainSeq1 = np.array(y_array1)\n",
        "\n",
        "X_trainSeq2 = np.array(X_array2)\n",
        "y_trainSeq2 = np.array(y_array2)\n",
        "\n",
        "## CNN grayscale only ##\n",
        "#X_trainSeq1 = X_trainSeq1[..., np.newaxis]\n",
        "#X_trainSeq2 = X_trainSeq2[..., np.newaxis]\n",
        "\n",
        "X_gen = generator.flow(X_trainSeq1, y_trainSeq1, batch_size = 1820, seed = random_state)\n",
        "X_trainGen1, y_trainGen1 = X_gen.next()\n",
        "X_trainSeq1Gen = np.concatenate((X_trainSeq1, X_trainGen1), axis=0)\n",
        "y_trainSeq1Gen = np.concatenate((y_trainSeq1, y_trainGen1), axis=0)\n",
        "while i < 10:\n",
        "    X_trainGen1, y_trainGen1 = X_gen.next()\n",
        "    X_trainSeq1Gen = np.concatenate((X_trainSeq1Gen, X_trainGen1), axis=0)\n",
        "    y_trainSeq1Gen = np.concatenate((y_trainSeq1Gen, y_trainGen1), axis=0)\n",
        "    i += 1\n",
        "i = 0\n",
        "\n",
        "X_gen = generator.flow(X_trainSeq2, y_trainSeq2, batch_size = 329, seed = random_state)\n",
        "X_trainGen2, y_trainGen2 = X_gen.next()\n",
        "X_trainSeq2Gen = np.concatenate((X_trainSeq2, X_trainGen2), axis=0)\n",
        "y_trainSeq2Gen = np.concatenate((y_trainSeq2, y_trainGen2), axis=0)\n",
        "while i < 60:\n",
        "    X_trainGen2, y_trainGen2 = X_gen.next()\n",
        "    X_trainSeq2Gen = np.concatenate((X_trainSeq2Gen, X_trainGen2), axis=0)\n",
        "    y_trainSeq2Gen = np.concatenate((y_trainSeq2Gen, y_trainGen2), axis=0)\n",
        "    i += 1\n",
        "\n",
        "counter_set1 = X_trainSeq1Gen.shape[0]\n",
        "counter_set2 = X_trainSeq2Gen.shape[0]\n",
        "\n",
        "X_totalTrainSet = np.concatenate((X_trainSeq1Gen, X_trainSeq2Gen), axis=0)\n",
        "y_totalTrainSet = np.concatenate((y_trainSeq1Gen, y_trainSeq2Gen), axis=0)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_totalTrainSet, y_totalTrainSet, train_size = train_valid_size, random_state = random_state, stratify = y_totalTrainSet)\n",
        "\n",
        "del X_array1\n",
        "del y_array1\n",
        "del X_array2\n",
        "del y_array2\n",
        "del X_trainSeq1\n",
        "del y_trainSeq1\n",
        "del X_trainSeq2\n",
        "del y_trainSeq2\n",
        "del X_trainGen1\n",
        "del y_trainGen1\n",
        "del X_trainGen2\n",
        "del y_trainGen2\n",
        "del X_trainSeq1Gen\n",
        "del y_trainSeq1Gen\n",
        "del X_trainSeq2Gen\n",
        "del y_trainSeq2Gen\n",
        "del X_totalTrainSet\n",
        "del y_totalTrainSet\n",
        "del X_gen\n",
        "gc.collect()\n",
        "\n",
        "print('treinamento:         ', X_train.shape)\n",
        "print('validação:           ', X_valid.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# enumerate the classes found\n",
        "class_names = ['cpu', 'gpu', 'mobo', 'ram', 'hd', 'ssd-sata', 'ssd-m2']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train/validation/test dataset visualization (100 first items)\n",
        "n_rows = 10\n",
        "n_cols = 10\n",
        "plt.figure(figsize = (n_cols * 1.2, n_rows * 1.2))\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        index = n_cols * row + col\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(X_train[index, :, :], cmap = 'binary')\n",
        "        plt.axis('off')\n",
        "        plt.title(class_names[y_train[index]], fontsize = font_size / 2, color = font_color)\n",
        "plt.subplots_adjust(wspace = 0.2, hspace = 0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## CNN ##\n",
        "\n",
        "epochs = 12\n",
        "\n",
        "# build the neural network layers\n",
        "keras.backend.clear_session() # clears the session\n",
        "np.random.seed(random_state) # random tf seed, but fixed\n",
        "tf.random.set_seed(random_state) # random tf seed, but fixed\n",
        "if 'model' in globals():\n",
        "        del model\n",
        "        gc.collect()\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "                keras.layers.Conv2D(filters = 32, kernel_size = 5, strides = 1, padding = 'same', activation = 'relu', input_shape = [64, 64, 3]),           \n",
        "                keras.layers.MaxPool2D(pool_size = 2),\n",
        "                keras.layers.Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),              \n",
        "                keras.layers.MaxPool2D(pool_size = 2),  \n",
        "                keras.layers.Conv2D(filters = 96, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu'),              \n",
        "                keras.layers.MaxPool2D(pool_size = 2), \n",
        "                keras.layers.Flatten(),\n",
        "                keras.layers.Dropout(0.5),\n",
        "                keras.layers.Dense(512, activation = 'relu'),\n",
        "                keras.layers.Dropout(0.25),\n",
        "                keras.layers.Dense(256, activation = 'relu'),\n",
        "                keras.layers.Dropout(0.25),\n",
        "                keras.layers.Dense(64, activation = 'relu'),\n",
        "                keras.layers.Dense(7, activation = 'softmax')\n",
        "        ])        \n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# prints the DNN/CNN structure\n",
        "tf.keras.utils.plot_model(model, 'pc_hardware_model.png', show_shapes = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp = round((1 - train_valid_size) * 100, 2)\n",
        "\n",
        "# sets NADAM as the optimizer (CNN)\n",
        "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'nadam', metrics = ['accuracy'])\n",
        "\n",
        "run_dir1 = os.path.join(log_dir, 'cnn' + '-' + 'nadam' + '_' + 'eph' + str(epochs) + '_' + 'img' + str(X_train.shape[0] + X_valid.shape[0]) + '_' + str(64) + 'x' + str(64) + '_' + str(train_valid_size * 100) + '%' + '-' + str(temp) + '%' + '-' + '_' + time.strftime('run-%Y-%m-%d-%H-%M-%S'))\n",
        "tensorboard1 = keras.callbacks.TensorBoard(run_dir1)\n",
        "\n",
        "# trains the neural network\n",
        "%time history = model.fit(X_train, y_train, epochs = epochs, validation_data = (X_valid, y_valid), callbacks = [tensorboard1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# prints the convergence graph\n",
        "pd.DataFrame(history.history).plot(figsize=(12, 6))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# loads Tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=./logs --port=6006"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# function to gather pictures and generate a numpy array (COLOR)\n",
        "def create_dataset2(img_folder):\n",
        "   \n",
        "    counter_set1 = 0\n",
        "    img_data_array = []\n",
        "    class_name = []\n",
        "   \n",
        "    for dir1 in os.listdir(img_folder):\n",
        "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
        "            image_path = os.path.join(img_folder, dir1, file)\n",
        "            image = io.imread(image_path, as_gray = False)\n",
        "            image = np.array(image, dtype = 'float32')  \n",
        "            image /= 255          \n",
        "            img_data_array.append(image)\n",
        "            class_name.append(int(dir1))\n",
        "            counter_set1 += 1\n",
        "    return img_data_array, class_name, counter_set1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# function to gather pictures and generate a numpy array (GRAYSCALE)\n",
        "def create_dataset2(img_folder):\n",
        "   \n",
        "    counter_set1 = 0\n",
        "    img_data_array = []\n",
        "    class_name = []\n",
        "   \n",
        "    for dir1 in os.listdir(img_folder):\n",
        "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
        "            image_path = os.path.join(img_folder, dir1, file)\n",
        "            image = io.imread(image_path, as_gray = True)\n",
        "            image = util.invert(image)\n",
        "            image = np.array(image, dtype = 'float32')\n",
        "            image /= 255\n",
        "            img_data_array.append(image)\n",
        "            class_name.append(int(dir1))\n",
        "    return img_data_array, class_name, counter_set1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dataset import\n",
        "X_array2, y_array2, counter_set1 = create_dataset2(img_test_folder)\n",
        "\n",
        "X_test = np.array(X_array2)\n",
        "y_test = np.array(y_array2)\n",
        "\n",
        "## CNN grayscale only ##\n",
        "#X_test = X_test[..., np.newaxis]\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "X_test, y_test = shuffle(X_test, y_test, random_state = random_state)\n",
        "\n",
        "print('testes finais:              ', X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# prints the error data\n",
        "print('erro de treino:   ', history.history['loss'][-1])\n",
        "print('erro de validação:', history.history['val_loss'][-1])\n",
        "print('erro de teste:    ', model.evaluate(X_test, y_test, verbose = 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# probabilities for the first 100 test instances\n",
        "X_new = X_test[:]\n",
        "y_proba = model.predict(X_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# predicted classes for the same 100 test instances\n",
        "y_pred = np.argmax(model.predict(X_new), axis = -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test dataset evaluation view\n",
        "n_rows = 12\n",
        "n_cols = 12\n",
        "plt.figure(figsize = (n_cols * 1.2, n_rows * 1.2))\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        index = n_cols * row + col\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(X_new[index, :, :], cmap = 'binary')\n",
        "        plt.axis('off')\n",
        "        plt.title(class_names[y_pred[index]], fontsize = font_size / 2, color = font_color)\n",
        "plt.subplots_adjust(wspace = 0.2, hspace = 0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# show probability percentage\n",
        "for image_index in range(30):\n",
        "    plt.imshow(X_test[image_index])\n",
        "    plt.show()\n",
        "    for class_name, class_id in zip(class_names, y_proba[image_index]):\n",
        "        print('{} - {:.2f}%'.format(class_name, class_id.round(2) * 100))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# saves the CNN neural network\n",
        "model.save('cnn' + '-' + 'nadam' + '_' + 'eph' + str(epochs) + '_' + 'img' + str(X_train.shape[0] + X_valid.shape[0]) + '_' + str(64) + 'x' + str(64) + '_' + str(train_valid_size * 100) + '%' + '-' + '%' + '-' + str(temp) + '%' + '-' + str(100 - (train_valid_size * 100) - temp) + '%' + '_' + time.strftime('run-%Y-%m-%d-%H-%M-%S') + '.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Furg - ECD 07 - Machine Learning I - Redes neurais (parte 1)",
      "provenance": []
    },
    "interpreter": {
      "hash": "d51d984da6a6cd08cca53f3158375701e5ce3d1747f30cf348ef56f2bbf24d41"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('venv': venv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "nav_menu": {
      "height": "264px",
      "width": "369px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
