{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Zd1JPPl0FzD_"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import cv2\n",
        "import sys\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pydot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkyCmdMqFzEN"
      },
      "source": [
        "# Construindo um classificador de imagens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMG_WIDTH=128\n",
        "IMG_HEIGHT=128\n",
        "img_folder=r'dataset\\pictures\\train\\128x128'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# auxiliary code to visualize all pictures of dataset\n",
        "plt.figure(figsize=(20,20))\n",
        "list_of_files=os.listdir(img_folder)\n",
        "number_of_files=len(list_of_files)\n",
        "\n",
        "for i in range(number_of_files):\n",
        "    file = random.choice(os.listdir(img_folder))\n",
        "    image_path= os.path.join(img_folder, file)\n",
        "    img=mpimg.imread(image_path)\n",
        "    ax=plt.subplot(12,12,i+1)\n",
        "    ax.title.set_text(file)\n",
        "    plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# function to gather pictures and generate a numpy array\n",
        "def create_dataset(img_folder):\n",
        "   \n",
        "    img_data_array = []\n",
        "    class_name = []\n",
        "   \n",
        "    for dir1 in os.listdir(img_folder):\n",
        "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
        "            image_path = os.path.join(img_folder, dir1, file)\n",
        "            image= cv2.imread( image_path, cv2.COLOR_BGR2RGB)\n",
        "            image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
        "            image=np.array(image)\n",
        "            image = image.astype('float32')\n",
        "            image /= 255 \n",
        "            img_data_array.append(image)\n",
        "            class_name.append(dir1)\n",
        "    return img_data_array, class_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# extract the image array and class name\n",
        "img_data, class_name = create_dataset(img_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# auxiliary code to visualize the array generated from the pictures\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "print(img_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'cpu': 0, 'gpu': 1, 'mobo': 2, 'ram': 3}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_dict={k: v for v, k in enumerate(np.unique(class_name))}\n",
        "target_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_val=  [target_dict[class_name[i]] for i in range(len(class_name))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "model=tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.InputLayer(input_shape=(IMG_HEIGHT,IMG_WIDTH, 3)),\n",
        "            tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
        "            tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(6)\n",
        "        ])\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "3/3 [==============================] - 1s 83ms/step - loss: 12.4450 - accuracy: 0.1667\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 12.2805 - accuracy: 0.2381\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 12.2805 - accuracy: 0.2381\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 0s 80ms/step - loss: 12.2805 - accuracy: 0.2381\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 12.2805 - accuracy: 0.2381\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(x=np.array(img_data, np.float32), y=np.array(list(map(int,target_val)), np.float32), epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0E6IrPzBFzEN"
      },
      "source": [
        "O primeiro passo é carregar um conjunto de dados. No caso, usamos aqui o _dataset_ **Fashion MNIST**, com imagens reduzidas de roupas. A biblioteca Keras tem várias funções para carregar conjuntos de dados populares em `keras.datasets`. \n",
        "\n",
        "O conjunto de dados já está dividido entre instâncias de treinamento e de teste, mas a seguir iremos dividir o conjunto de treinamento para ter um conjunto de validação.\n",
        "\n",
        "Cada instância é uma imagem em tons de cinza (com valores de 0 a 255) e com resolução 28 por 28 _pixels_. Note que esse _dataset_ foi feito para ser compatível com o conjunto **MNIST** original, tendo a mesma resolução, número de instâncias e número de classes (10), porém sendo mais desafiador de classificar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLndlrWDFzEN"
      },
      "outputs": [],
      "source": [
        "# importação do dataset\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
        "print('treinamento completo:', X_train_full.shape)\n",
        "print('testes:              ', X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlgS9wV7FzEO"
      },
      "source": [
        "Aqui o conjunto completo de treinamento é quebrado em dois, um de treinamento menor e outro de validação. Também é feita a conversão dos valores inteiros de tons de cinza (de 0 a 255) para um vaor real no intervalo de 0 a 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGMH56oyFzEO"
      },
      "outputs": [],
      "source": [
        "# separação dos dados de treinamento e validação\n",
        "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_test = X_test / 255.\n",
        "print('treinamento:', X_train.shape)\n",
        "print('validação:   ', X_valid.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q30n0bRcFzEP"
      },
      "source": [
        "Abaixo é exibida primeira instância do conjunto de treino:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2DORva5FzEP"
      },
      "outputs": [],
      "source": [
        "plt.imshow(X_train[0], cmap='binary')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goHku5LZFzEQ"
      },
      "source": [
        "Os rótulos são valores inteiros de 0 a 9, quardados nos vetores `y` e que correspondem aos seguintes nomes de classes.\n",
        "\n",
        "Então a instância 0 é um **casaco**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOtQdsMMFzEQ"
      },
      "outputs": [],
      "source": [
        "class_names = ['camiseta', 'calça', 'pulôver', 'vestido', 'casaco',\n",
        "               'sandália', 'camisa', 'tênis', 'bolsa', 'bota']\n",
        "class_names[y_train[0]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R2IFwKhFzER"
      },
      "source": [
        "Abaixo é exibido um mosaico com várias instâncias do conjunto de treino:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S67rSQ9vFzER"
      },
      "outputs": [],
      "source": [
        "# não se preocupe com este código\n",
        "\n",
        "n_rows = 4\n",
        "n_cols = 10\n",
        "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        index = n_cols * row + col\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(X_train[index], cmap='binary')\n",
        "        plt.axis('off')\n",
        "        plt.title(class_names[y_train[index]], fontsize=12)\n",
        "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6K9zoE5FzER"
      },
      "source": [
        "# Criando uma rede neural\n",
        "\n",
        "Aqui vamos criar uma rede neural de classificação, usando um modelo (ou arquitetura) do tipo sequencial. O modelo sequencial corresponde ao tipo mais simples de rede neural, onde uma sequência de camadas de neurônios é empilhada uma em cima da outra.\n",
        "\n",
        "- A criação começa com a chamada a `Sequential`, que define o tipo do modelo:\n",
        "\n",
        "        model = keras.models.Sequential()\n",
        "\n",
        "- Então uma camada do tipo `Flatten` é adicionada. Seu papel é apenas transformar a matriz de _pixels_ em um longo vetor. É uma camada de preprocessamento dos dados. Mas como esta é a primeira camada, é preciso definir o formato da entrada com `input_shape`:\n",
        "\n",
        "        model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "\n",
        "- A seguir adicionamos uma camada densa do tipo `Dense`, ou seja, totalmente conectada com a camada anterior. Esta conta com 300 neurônios e função de ativação ReLU:\n",
        "\n",
        "        model.add(keras.layers.Dense(300, activation='relu'))\n",
        "        \n",
        "- Então uma segunda camada `Dense` é adicionada, agora com 100 neurônios e função de ativação também ReLU:\n",
        "        \n",
        "        model.add(keras.layers.Dense(100, activation='relu'))\n",
        "        \n",
        "- Finalmente uma camada de saída é adicionada. Aqui o tipo também é `Dense`, mas a função de ativação é trocada para `softmax` para produzir a saída de classificador (uma vez que as classes são mutuamente exclusivas):\n",
        "        \n",
        "        model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "Ainda que se possa criar uma rede neural com as diversas chamadas a `model.add(...)`, é mais conveniente criar o modelo passando uma lista de camadas, como mostrado a seguir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqaIO9f8FzES"
      },
      "outputs": [],
      "source": [
        "# comando para 'zerar' a biblioteca Keras\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# definição de sementes aleatórias\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOH7jRFvFzET"
      },
      "outputs": [],
      "source": [
        "# especificação do modelo\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation='relu'),\n",
        "    keras.layers.Dense(100, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENAuv2WqFzET"
      },
      "outputs": [],
      "source": [
        "# resumo legível da arquitetura deste modelo\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A74KcxDiFzEU"
      },
      "source": [
        "Note que as camadas densas geralmente têm muitos parâmetros. Por exemplo, a primeira camada densa tem pesos de conexão de 784 × 300, além de mais 300 termos de _bias_, chegando a um total de 235.500 parâmetros.\n",
        "\n",
        "Isso dá ao modelo bastante flexibilidade para ajustar os dados de treinamento, mas também significa que o modelo corre o risco de ter _overfitting_, especialmente quando não há muitos dados de treinamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F29enauHFzEU"
      },
      "source": [
        "## Arquitetura da rede neural\n",
        "\n",
        "Podemos gerar uma figura da arquitetura deste modelo usando a função `keras.utils.plot_model`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHEgELLyFzEU"
      },
      "outputs": [],
      "source": [
        "keras.utils.plot_model(model, 'fashion_mnist_model.png', show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgZ2qIcqFzEV"
      },
      "source": [
        "## Acesso às camadas\n",
        "\n",
        "A biblioteca permite acessar cada camada criada, usando índices de acesso tal como em uma lista de Python.\n",
        "\n",
        "Permite também ver atributos de cada camada, como o nome ou se é uma camada oculta. E ainda permite inspecionar os pesos de todas as conexões daquela camada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSWwPE5VFzEV"
      },
      "outputs": [],
      "source": [
        "# acesso a cada uma das camadas\n",
        "model.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9V8rBsVoFzEW"
      },
      "outputs": [],
      "source": [
        "# primeira camada e respectivo nome\n",
        "hidden1 = model.layers[1]\n",
        "hidden1.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hvf9hgcFFzEW"
      },
      "outputs": [],
      "source": [
        "# encontra camada pelo nome\n",
        "model.get_layer(hidden1.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFZUVqN2FzEY"
      },
      "outputs": [],
      "source": [
        "# indica se a camada é ou não oculta\n",
        "model.get_layer(hidden1.name) is hidden1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9l7CapdFzEY"
      },
      "source": [
        "Observe que a camada `Dense` inicializa os pesos das conexão aleatoriamente. Os vieses foram inicializados apenas com zero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRjMc_BaFzEY"
      },
      "outputs": [],
      "source": [
        "# obtém pesos e vieses da camada\n",
        "weights, biases = hidden1.get_weights()\n",
        "print('weights:', weights.shape)\n",
        "print('biases: ', biases.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkvaAq_uFzEZ"
      },
      "outputs": [],
      "source": [
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxX2GKzJFzEZ"
      },
      "outputs": [],
      "source": [
        "biases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmJF24bjFzEa"
      },
      "source": [
        "## Compilando a rede neural\n",
        "\n",
        "Depois que um modelo é criado, é preciso chamar o método `compile()`, especificando a **função de perda** (aqui, a função `sparse_categorical_crossentropy`) e o **otimizador** a ser usado (`sgd`, algoritmo de descida do gradiente estocástico).\n",
        "\n",
        "Opcionalmente, você também pode especificar uma lista de **medidas de desempenho** extras para calcular durante o treinamento e avaliação. Neste caso apenas é indicada a acurácia com `accuracy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8qZT7UdFzEa"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', \n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVeVoB2qFzEa"
      },
      "source": [
        "# Treinando e avaliando a rede neural\n",
        "\n",
        "Para treinar o modelo basta chamar o método `fit()`. \n",
        "\n",
        "Três parâmetros são obrigatórios: as _features_ de treinamento, os rótulos de treinamento e o número de épocas.\n",
        "\n",
        "Cada **época** (_epoch_) corresponde a uma etapa de atualização da rede neural.\n",
        "\n",
        "Opcionalemente é passado também um conjunto de validação. A biblioteca Keras medirá a perda e as métricas extras ao final de cada época, o que é muito útil para ver como o modelo realmente funciona: se o desempenho no conjunto de treinamento é muito melhor do que no conjunto de validação, provavelmente está ocorrendo _overfitting_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcTzUE33FzEb"
      },
      "outputs": [],
      "source": [
        "# esta chamada pode demorar um pouco\n",
        "%time history = model.fit(X_train, y_train, epochs=25, validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jK6oX2yFzEb"
      },
      "outputs": [],
      "source": [
        "# os dados do treinamento estão disponíveis no histórico retornado\n",
        "print('parâmetros:', history.params)\n",
        "print('métricas:  ', list(history.history.keys()))\n",
        "print('épocas:    ', history.epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VTFBTMdFzEb"
      },
      "source": [
        "## Visualização da evolução das métricas ao longo do treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXm1A2g8FzEb"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(12, 6))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGY2eqMnFzEc"
      },
      "source": [
        "## Avaliação final do modelo e geração de previsões"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8uKMDzAFzEc"
      },
      "outputs": [],
      "source": [
        "# avaliação com conjunto de teste\n",
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNbEZkq3FzEd"
      },
      "outputs": [],
      "source": [
        "# probabilidades computadas para três instâncias de teste\n",
        "X_new = X_test[:3]\n",
        "y_proba = model.predict(X_new)\n",
        "print(y_proba.round(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYxYZ4FcFzEd"
      },
      "outputs": [],
      "source": [
        "# classes previstas e reais para as mesmas três instâncias de teste\n",
        "y_pred = np.argmax(model.predict(X_new), axis=-1)\n",
        "print('previstas: ', np.array(class_names)[y_pred])\n",
        "print('reais:     ', np.array(class_names)[y_test[:3]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bz1zIy0dFzEe"
      },
      "outputs": [],
      "source": [
        "# visualização das tres instâncias\n",
        "plt.figure(figsize=(7.2, 2.4))\n",
        "for index, image in enumerate(X_new):\n",
        "    plt.subplot(1, 3, index + 1)\n",
        "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\")\n",
        "    plt.axis('off')\n",
        "    plt.title(class_names[y_test[index]], fontsize=12)\n",
        "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Furg - ECD 07 - Machine Learning I - Redes neurais (parte 1)",
      "provenance": []
    },
    "interpreter": {
      "hash": "d51d984da6a6cd08cca53f3158375701e5ce3d1747f30cf348ef56f2bbf24d41"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('venv': venv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "nav_menu": {
      "height": "264px",
      "width": "369px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
