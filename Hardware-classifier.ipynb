{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zd1JPPl0FzD_"
      },
      "outputs": [],
      "source": [
        "# import the necessary libraries\n",
        "import time\n",
        "import gc\n",
        "import os\n",
        "os.add_dll_directory(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.2/bin\")\n",
        "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'\n",
        "log_dir = os.path.join(os.curdir, 'logs')\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage import io\n",
        "from skimage.color import rgba2rgb\n",
        "from tensorflow import keras\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "# define the image path\n",
        "#img_train_folder = r'dataset\\pictures\\train\\128x128'\n",
        "img_train_folder = r'dataset\\pictures\\train\\64x64'\n",
        "\n",
        "#define plot properties\n",
        "font_size = 25\n",
        "font_color = 'white'\n",
        "plt.rc('axes', facecolor = '#1e1e1e')\n",
        "plt.rc('figure', facecolor = '#1e1e1e')\n",
        "plt.rc('axes', edgecolor = 'w')\n",
        "plt.rc('xtick', color = 'w')\n",
        "plt.rc('ytick', color = 'w')\n",
        "plt.rc('legend', facecolor = 'w')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# auxiliary code to visualize the first 10 pictures of each category\n",
        "plt.figure(figsize = (50, 50))\n",
        "j = 0\n",
        "counter1 = 0\n",
        "counter2 = 0\n",
        "\n",
        "for dir1 in os.listdir(img_train_folder):\n",
        "    for file in os.listdir(os.path.join(img_train_folder, dir1)):\n",
        "        image_path = os.path.join(img_train_folder, dir1, file)  \n",
        "        img = mpimg.imread(image_path)\n",
        "        ax = plt.subplot(10, 10, j+1)\n",
        "        ax.title.set_text(file)\n",
        "        plt.axis('off')\n",
        "        plt.title(dir1, fontsize = font_size, color = font_color)\n",
        "        plt.imshow(img)\n",
        "        j += 1\n",
        "        counter1 += 1\n",
        "        if counter1 == 10:\n",
        "            break\n",
        "    counter2 += 1\n",
        "    counter1 = 0\n",
        "    if counter2 == 7:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# function to gather pictures and generate a numpy array (COLOR)\n",
        "def create_dataset(img_folder):\n",
        "   \n",
        "    counter = 0\n",
        "    img_data_array = []\n",
        "    class_name = []\n",
        "   \n",
        "    for dir1 in os.listdir(img_folder):\n",
        "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
        "            image_path = os.path.join(img_folder, dir1, file)\n",
        "            image = io.imread(image_path, as_gray = False)\n",
        "            image = np.array(image)\n",
        "            image = rgba2rgb(image)                      \n",
        "            img_data_array.append(image)\n",
        "            class_name.append(int(dir1))\n",
        "    return img_data_array, class_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sets a image generator to inflate the dataset\n",
        "generator = ImageDataGenerator(\n",
        "    rotation_range = 360,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_test_size = 0.70\n",
        "valid_test_size = 0.66\n",
        "random_state = 42\n",
        "\n",
        "# dataset import\n",
        "X_array1, y_array1 = create_dataset(img_train_folder)\n",
        "\n",
        "X_trainSeq = np.array(X_array1)\n",
        "y_trainSeq = np.array(y_array1)\n",
        "\n",
        "X_gen = generator.flow(X_trainSeq, y_trainSeq, batch_size = 14336, seed = random_state)\n",
        "X_trainGen, y_trainGen = X_gen.next()\n",
        "X_trainSeqGen = np.concatenate((X_trainSeq, X_trainGen), axis=0)\n",
        "y_trainSeqGen = np.concatenate((y_trainSeq, y_trainGen), axis=0)\n",
        "X_trainGen, y_trainGen = X_gen.next()\n",
        "X_trainSeqGen = np.concatenate((X_trainSeqGen, X_trainGen), axis=0)\n",
        "y_trainSeqGen = np.concatenate((y_trainSeqGen, y_trainGen), axis=0)\n",
        "\n",
        "counter = X_trainSeqGen.shape[0]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_trainSeqGen, y_trainSeqGen, train_size = train_test_size, random_state = random_state, stratify = y_trainSeqGen)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, train_size = valid_test_size, random_state = random_state, stratify = y_test)\n",
        "\n",
        "del X_array1\n",
        "del y_array1\n",
        "del X_trainSeq\n",
        "del y_trainSeq\n",
        "del X_trainGen\n",
        "del y_trainGen\n",
        "del X_trainSeqGen\n",
        "del y_trainSeqGen\n",
        "del X_gen\n",
        "gc.collect()\n",
        "\n",
        "print('treinamento completo:', X_train.shape)\n",
        "print('validação:           ', X_valid.shape)\n",
        "print('testes:              ', X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# checks if all categories are evenly distributed\n",
        "unique, counts = np.unique(y_train, return_counts = True)\n",
        "print(dict(zip(unique, counts)))\n",
        "\n",
        "unique, counts = np.unique(y_valid, return_counts = True)\n",
        "print(dict(zip(unique, counts)))\n",
        "\n",
        "unique, counts = np.unique(y_test, return_counts = True)\n",
        "print(dict(zip(unique, counts)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# enumerate the classes found\n",
        "class_names = ['cpu', 'gpu', 'mobo', 'ram', 'hd', 'ssd-sata', 'ssd-m2']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train dataset visualization (100 first items)\n",
        "n_rows = 5\n",
        "n_cols = 20\n",
        "plt.figure(figsize = (n_cols * 1.2, n_rows * 1.2))\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        index = n_cols * row + col\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(X_train[index, :, :], cmap = 'binary')\n",
        "        plt.axis('off')\n",
        "        plt.title(class_names[y_train[index]], fontsize = font_size / 2, color = font_color)\n",
        "plt.subplots_adjust(wspace = 0.2, hspace = 0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# validation dataset visualization (100 first items)\n",
        "n_rows = 5\n",
        "n_cols = 20\n",
        "plt.figure(figsize = (n_cols * 1.2, n_rows * 1.2))\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        index = n_cols * row + col\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(X_valid[index, :, :], cmap = 'binary')\n",
        "        plt.axis('off')\n",
        "        plt.title(class_names[y_valid[index]], fontsize = font_size / 2, color = font_color)\n",
        "plt.subplots_adjust(wspace = 0.2, hspace = 0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test dataset visualization (100 first items)\n",
        "n_rows = 5\n",
        "n_cols = 20\n",
        "plt.figure(figsize = (n_cols * 1.2, n_rows * 1.2))\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        index = n_cols * row + col\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(X_test[index, :, :], cmap = 'binary')\n",
        "        plt.axis('off')\n",
        "        plt.title(class_names[y_test[index]], fontsize = font_size / 2, color = font_color)\n",
        "plt.subplots_adjust(wspace = 0.2, hspace = 0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# visualization of the first instance from the train dataset\n",
        "plt.imshow(X_train[0], cmap = 'binary')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# visualization of the first instance from the validation dataset\n",
        "plt.imshow(X_valid[0], cmap = 'binary')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# visualization of the first instance from the test dataset\n",
        "plt.imshow(X_test[0], cmap = 'binary')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# auxiliary code to visualize the array generated from the pictures\n",
        "#np.set_printoptions(threshold=sys.maxsize)\n",
        "#print(X_train[0])\n",
        "print(X_valid[0])\n",
        "#print(X_test[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# auxiliary code to visualize the label of the picture\n",
        "#np.set_printoptions(threshold=sys.maxsize)\n",
        "print(y_train[0])\n",
        "#print(y_valid[0])\n",
        "#print(y_test[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# shows the class of the first instance of the train dataset\n",
        "class_names[y_train[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# shows the class of the first instance of the validation dataset\n",
        "class_names[y_valid[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# shows the class of the first instance of the test dataset\n",
        "class_names[y_test[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## CNN ##\n",
        "dimensionR     = 64\n",
        "dimensionC     = 64\n",
        "channels       = 3\n",
        "classes        = 7\n",
        "filters        = 16\n",
        "activation     = 'relu'\n",
        "activation_out = 'softmax'\n",
        "kernel_size    = 3\n",
        "strides        = 1\n",
        "padding        = 'same'\n",
        "epochs         = 10\n",
        "callbacks      = []     # [keras.callbacks.EarlyStopping(patience=10)]\n",
        "\n",
        "# build the neural network layers\n",
        "keras.backend.clear_session() # clears the session\n",
        "np.random.seed(random_state) # random numpy seed, but fixed\n",
        "tf.random.set_seed(random_state) # random tf seed, but fixed\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "                keras.layers.Conv2D(filters, kernel_size = kernel_size, strides = strides, padding = padding, activation = activation, input_shape = [dimensionR, dimensionC, channels]),\n",
        "                keras.layers.Conv2D(filters * 2, kernel_size = kernel_size, strides = strides, padding = padding, activation = activation),\n",
        "                keras.layers.MaxPool2D(pool_size = 2),\n",
        "                keras.layers.Conv2D(filters * 4, kernel_size = kernel_size, strides = strides, padding = padding, activation = activation),\n",
        "                keras.layers.Conv2D(filters * 8, kernel_size = kernel_size, strides = strides, padding = padding, activation = activation),\n",
        "                keras.layers.Flatten(),\n",
        "                keras.layers.Dropout(0.25),\n",
        "                keras.layers.Dense(filters * 16, activation = activation),\n",
        "                keras.layers.Dropout(0.5),\n",
        "                keras.layers.Dense(filters * 16, activation = activation),\n",
        "                keras.layers.Dense(7, activation = activation_out)\n",
        "        ])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# prints the DNN/CNN structure\n",
        "tf.keras.utils.plot_model(model, 'pc_hardware_model.png', show_shapes = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp = round((1 - train_test_size) * valid_test_size * 100, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sets NADAM as the optimizer (CNN)\n",
        "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'nadam', metrics = ['accuracy'])\n",
        "\n",
        "run_dir1 = os.path.join(log_dir, 'cnn' + '-' + 'nadam' + '_' + 'eph' + str(epochs) + '_' + 'img' + str(counter) + '_' + str(dimensionR) + 'x' + str(dimensionC) + '_' + str(train_test_size * 100) + '%' + '-' + str(temp) + '%' + '-' + str(100 - (train_test_size * 100) - temp) + '%' + '_' + time.strftime('run-%Y-%m-%d-%H-%M-%S'))\n",
        "tensorboard1 = keras.callbacks.TensorBoard(run_dir1)\n",
        "\n",
        "# trains the neural network\n",
        "%time history = model.fit(X_train, y_train, epochs = epochs, validation_data = (X_valid, y_valid), callbacks = [tensorboard1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# prints the convergence graph\n",
        "pd.DataFrame(history.history).plot(figsize=(12, 6))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# prints the error data\n",
        "print('erro de treino:   ', history.history['loss'][-1])\n",
        "print('erro de validação:', history.history['val_loss'][-1])\n",
        "print('erro de teste:    ', model.evaluate(X_test, y_test, verbose = 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# loads Tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=./logs --port=6006"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# probabilities for the first 200 test instances\n",
        "X_new = X_test[:200]\n",
        "y_proba = model.predict(X_new)\n",
        "print(y_proba.round(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# predicted classes for the same 200 test instances\n",
        "y_pred = np.argmax(model.predict(X_new), axis = -1)\n",
        "print('previstas: ', np.array(class_names)[y_pred])\n",
        "print('reais:     ', np.array(class_names)[y_test[:200]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test dataset evaluation view\n",
        "n_rows = 5\n",
        "n_cols = 20\n",
        "plt.figure(figsize = (n_cols * 1.2, n_rows * 1.2))\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        index = n_cols * row + col\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(X_new[index, :, :], cmap = 'binary')\n",
        "        plt.axis('off')\n",
        "        plt.title(class_names[y_pred[index]], fontsize = font_size / 2, color = font_color)\n",
        "plt.subplots_adjust(wspace = 0.2, hspace = 0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# saves the CNN neural network\n",
        "model.save('cnn' + '-' + 'nadam' + '_' + 'eph' + str(epochs) + '_' + 'img' + str(counter) + '_' + str(dimensionR) + 'x' + str(dimensionC) + '_' + str(train_test_size * 100) + '%' + '-' + '%' + '-' + str(temp) + '%' + '-' + str(100 - (train_test_size * 100) - temp) + '%' + '_' + time.strftime('run-%Y-%m-%d-%H-%M-%S') + '.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Furg - ECD 07 - Machine Learning I - Redes neurais (parte 1)",
      "provenance": []
    },
    "interpreter": {
      "hash": "d51d984da6a6cd08cca53f3158375701e5ce3d1747f30cf348ef56f2bbf24d41"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('venv': venv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "nav_menu": {
      "height": "264px",
      "width": "369px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
